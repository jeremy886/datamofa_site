<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Mofa - Magic in Data</title><link>http://www.datamofa.club/</link><description>Learning and Teaching Big Data</description><atom:link href="http://www.datamofa.club/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 16 Mar 2018 06:12:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Data Analysis Tools - Week 1: Hypothesis Testing and ANOVA</title><link>http://www.datamofa.club/posts/data-analysis-tools-week-1-hypothesis-testing-and-anova/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;Here I will explore the association of Life Expectacy and Country Income Level.&lt;/p&gt;
&lt;p&gt;Please follow this link for my Jupyter-Notebook on github. &lt;a class="reference external" href="https://github.com/jeremy886/learn_datascience/blob/master/statistics/data_analysis_tools/week1-lab-Hypothesis%20Testing%20and%20ANOVA.ipynb"&gt;Link to Jupyter-Notebook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thank you.&lt;/p&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/data-analysis-tools-week-1-hypothesis-testing-and-anova/</guid><pubDate>Fri, 16 Mar 2018 05:59:48 GMT</pubDate></item><item><title>Case Study: Centrelink’s robo debt recovery system</title><link>http://www.datamofa.club/posts/case-study-centrelinks-robo-debt-recovery-system/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;This is part of the assignments for Data Science Ethics.&lt;/p&gt;
&lt;h2&gt;Case Study: Centrelink's robo debt recovery system&lt;/h2&gt;
&lt;h3&gt;Introduction:&lt;/h3&gt;
&lt;p&gt;Cenrelink is an Australian government agency in charge of "deliver social security payments and services to Australians." Since 2016, the agency implemented a debt recovery system without human intervention to recovery so-called "over payment" using black-box algorithms. It was believed that before the system was in place, the agency issued about 20,000 interventions (debt recovery letters) a year but now the same interventions just a week. The government agency said one in five incidents were resolved without a debt being issued and critics said that this was evidence of 20 per cent error rate.&lt;/p&gt;
&lt;p&gt;Listening to this audio report &lt;a href="http://www.abc.net.au/radionational/programs/backgroundbriefing/2017-03-05/8319442" title="Audio: How Centrelink's 'robodebt' ran off the rails"&gt;1&lt;/a&gt; and reading stories on this website &lt;a href="https://notmydebt.com.au/stories/notmydebt-stories" title="NotMyDebt Stories"&gt;2&lt;/a&gt;, the system sounds very flawed and unfair. People have identified miscalculation of the algorithms. From the stories available online, it appears the government puts the responsibilities of proofing accuracy and resolution of debt onto the vulnerable people and has an intention to maximise financial gains.&lt;/p&gt;
&lt;p&gt;Thanks to the Guardian news website, you can view news about this saga chronologically &lt;a href="https://www.theguardian.com/australia-news/centrelink-debt-recovery" title="Centrelink Debt Recovery"&gt;3&lt;/a&gt;. ABC (Australian Broadcasting Corporation) also provides a big picture here of the incident &lt;a href="http://www.abc.net.au/news/2017-03-03/centrelink-debt-controversy-what-is-robodebt/8317764" title="We're all talking about the Centrelink debt controversy, but what is 'robodebt' anyway?"&gt;4&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Data Science&lt;/h3&gt;
&lt;h4&gt;Social Impact&lt;/h4&gt;
&lt;p&gt;From the NotMyDebt website, there are about 650 stories and 4.3 million dollars of debt reported. It was also reported that tens of thousands of debts were wiped or reduced &lt;a href="https://www.theguardian.com/australia-news/2017/sep/13/centrelink-scandal-tens-of-thousands-of-welfare-debts-wiped-or-reduced" title="Centrelink scandal: tens of thousands of welfare debts wiped or reduced"&gt;5&lt;/a&gt;. This incident definitely has a big social impact and the question over validity and ethics is on solid ground.&lt;/p&gt;
&lt;h4&gt;Privacy and Validity&lt;/h4&gt;
&lt;p&gt;We tend to believe the government will do the right thing so we often surrender our privacy and entrust all our personal data to it. We also expect the government will make sure its decisions are reasonable and right before carrying it out. Unfortunately it seems not the case here.&lt;/p&gt;
&lt;h4&gt;Code of Ethics&lt;/h4&gt;
&lt;p&gt;Hidden behind the heavy door of the government bureau, a person or a group of them have implemented some kinds of Data Science techniques. Can we examine if the proposed two rules of Jagadish's Code of Ethics here apply to both the agency and the data scientist?&lt;/p&gt;
&lt;h4&gt;Do not surprise&lt;/h4&gt;
&lt;p&gt;First, do we expect the government to use our data to catch wrong -doings?  Some people may argue that if you do nothing wrong, you won't be in trouble. But this doesn't set the boundary of what the government can or can't do with our data. Second, is using data science techniques without humans in the loop also a surprise? &lt;/p&gt;
&lt;h4&gt;Own the outcomes&lt;/h4&gt;
&lt;p&gt;If you follow the stories &lt;a href="https://www.theguardian.com/australia-news/centrelink-debt-recovery" title="Centrelink Debt Recovery"&gt;3&lt;/a&gt;, it doesn't give an impression that the minister or the government is owning the outcomes at all. The minister believed the system works well but he can't be sure about many details and later remedies were made to prove that the system was not perfect. The biggest issue here is lack of transparency so we do really know that to what extent the government is right or the journalist is correct.&lt;/p&gt;
&lt;p&gt;For individual data scientists, it is very easy to weigh the human costs in their algorithms in hindsight but the mistake was made. Can you really uphold these two "simple" principles in your job when you are working at a big organisation like the government? Are there factors contributing to the difficulties of foreseeing the problems? &lt;/p&gt;
&lt;p&gt;I also think that without a professional board or committee, it would be a lot harder to point out the problem or "say no" to things against the principle.&lt;/p&gt;
&lt;h3&gt;References:&lt;/h3&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;[1]: http://www.abc.net.au/radionational/programs/backgroundbriefing/2017-03-05/8319442 "Audio: How Centrelink's 'robodebt' ran off the rails"
[2]: https://notmydebt.com.au/stories/notmydebt-stories "NotMyDebt Stories"
[3]: https://www.theguardian.com/australia-news/centrelink-debt-recovery "Centrelink Debt Recovery"
[4]: http://www.abc.net.au/news/2017-03-03/centrelink-debt-controversy-what-is-robodebt/8317764 "We're all talking about the Centrelink debt controversy, but what is 'robodebt' anyway?"
[5]: https://www.theguardian.com/australia-news/2017/sep/13/centrelink-scandal-tens-of-thousands-of-welfare-debts-wiped-or-reduced "Centrelink scandal: tens of thousands of welfare debts wiped or reduced"
&lt;/pre&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/case-study-centrelinks-robo-debt-recovery-system/</guid><pubDate>Sun, 18 Feb 2018 07:07:49 GMT</pubDate></item><item><title>Data Management and Visualization - week 4: Visualizing Data</title><link>http://www.datamofa.club/posts/data-management-and-visualization-week-4-visualizing-data/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;Finally, I have learnt a lot about seaborn and explore my data with the help of data visualization.&lt;/p&gt;
&lt;p&gt;I tried several plots provided by seaborn. I liked its simplicity and power in data visualization and I used
techniques taught in the lecture video but I feel it's not enough and I ended up spending a lot more time to
figure out all the details.&lt;/p&gt;
&lt;p&gt;In 4 weeks, I partially answered my question but it's not very satisfactory. More can be learnt in the area of
data visualization and statistics.&lt;/p&gt;
&lt;p&gt;Here is my week 4 assignment done in Jupyter-notebook. &lt;strong&gt;You need to click this link so you can follow along.&lt;/strong&gt;
&lt;a class="reference external" href="https://github.com/jeremy886/learn_datascience/blob/master/australia/week4_assignment.ipynb"&gt;Link to jupyter notebook&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/data-management-and-visualization-week-4-visualizing-data/</guid><pubDate>Wed, 14 Feb 2018 06:51:19 GMT</pubDate></item><item><title>Data Management and Visualization - week 3: Making Data Management Decisions</title><link>http://www.datamofa.club/posts/data-management-and-visualization-week-3-making-data-management-decisions/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;Here is my conclusion. More details are in my &lt;a class="reference external" href="https://github.com/jeremy886/learn_datascience/blob/master/australia/week3_assignment.ipynb"&gt;jupyter notebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Replacing missing values should make the data analysis more accurate and show a real picture.&lt;/p&gt;
&lt;p&gt;Here are the missing data:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;negative income -1 in the “income_low” column&lt;/li&gt;
&lt;li&gt;unknown income -99 in the “income_low” column&lt;/li&gt;
&lt;li&gt;unknown income -99 in the “income_high” column&lt;/li&gt;
&lt;li&gt;unknown income 9999 in the “income_high” column All are changed to nump.nan&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;When using qcut to explore the distribution of population, it’s discovered that the majority of population is fewer or equal to 3, accounting for nearly 50%. The reason is that Victoria has a relatively smaller population so the population per post code per income bracket is small. That can have an impact on analysis based on post code.&lt;/p&gt;
&lt;p&gt;I also created secondary variables and discover some meaningful facts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;“income” is created by averaging the lower and higher ends of the income brackets.&lt;/li&gt;
&lt;li&gt;“total_income” is created by timing “income” and “number” together. We made an assumption that the average income is the average of the lower and higher ends.&lt;/li&gt;
&lt;li&gt;Using the secondary variables, we can quickly tell the average weekly income ratio is, Female : Male = 591.53 : 773.68&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;To further explore the influence of post code (location), I extract top and bottom 10 income post codes. Since it’s difficult to use the post code alone, I try to map the code to suburb names. In the process, I realise the mapping is not perfect but I try it anyway because it is far more easier to interpreter the data by name.&lt;/p&gt;
&lt;p&gt;The analysis is not yet complete and I hope some data visualization techniques can help me discover more interesting areas I can use for further investigation next week.&lt;/p&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/data-management-and-visualization-week-3-making-data-management-decisions/</guid><pubDate>Wed, 07 Feb 2018 05:41:53 GMT</pubDate></item><item><title>Data Management and Visualization - week 2: Running Your First Program</title><link>http://www.datamofa.club/posts/data-management-and-visualization-week-2-running-your-first-program/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;Here is my work.&lt;/p&gt;
&lt;div class="section" id="thoughts"&gt;
&lt;h2&gt;Thoughts&lt;/h2&gt;
&lt;p&gt;I spent a lot of time creating workable data from the 2016 census files. I learnt a lot but it's also very time consuming.&lt;/p&gt;
&lt;p&gt;I also chose to use Jupyter-notebook this time instead of Spyder. It's simply a lot easier to explore data and ideas in Jupyter. I will also present my assignment in Jupyter. You can read me comments and programs over there.&lt;/p&gt;
&lt;p&gt;Assignment 2: &lt;a class="reference external" href="https://github.com/jeremy886/learn_datascience/blob/master/australia/week2_assignment.ipynb"&gt;Jupyter-notebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for your time and feedback.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/data-management-and-visualization-week-2-running-your-first-program/</guid><pubDate>Sat, 03 Feb 2018 09:11:00 GMT</pubDate></item><item><title>Research Project 1 for Data Visualization</title><link>http://www.datamofa.club/posts/research-project-1-for-data-visualization/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;div class="section" id="step-1-selection-of-data-set"&gt;
&lt;h2&gt;Step 1: Selection of Data Set&lt;/h2&gt;
&lt;p&gt;The data set is aggregated by the Australian Burea of Statistics from the 2016 census.&lt;/p&gt;
&lt;div class="section" id="source"&gt;
&lt;h3&gt;Source&lt;/h3&gt;
&lt;p&gt;Source of the data set: &lt;a class="reference external" href="https://datapacks.censusdata.abs.gov.au/datapacks/"&gt;the Australian Bureau of Statistics website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to download the files: &lt;a class="reference external" href="http://www.censusdata.abs.gov.au/CensusOutput/copsubdatapacks.nsf/All%20docs%20by%20catNo/2016_GCP_POA_for_Vic/%24File/2016_GCP_POA_for_Vic_short-header.zip?OpenElement&amp;amp;key=ded92a6f-4e19-ead5-9518-f22966129223"&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="step-2-topic-of-interest"&gt;
&lt;h2&gt;Step 2: Topic of Interest&lt;/h2&gt;
&lt;p&gt;Income, Gender and Residence&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Is Australian weekly income associated with sex?&lt;/li&gt;
&lt;li&gt;Is Australian weekly income associated with the postal code?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="step-3-codebook"&gt;
&lt;h2&gt;Step 3: Codebook&lt;/h2&gt;
&lt;p&gt;The Australian Bureau of Statistics (ABS) uses filename, sex and ages to differentiate data and this creates a unique way of storing data.&lt;/p&gt;
&lt;p&gt;After checking the meta files, I know income records are stored in these three files:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;2016Census_G17A_VIC_POA.csv&lt;/li&gt;
&lt;li&gt;2016Census_G17B_VIC_POA.csv&lt;/li&gt;
&lt;li&gt;2016Census_G17C_VIC_POA.csv&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="code"&gt;
&lt;h3&gt;Code&lt;/h3&gt;
&lt;div class="section" id="poa-code-2016-postal-areas-poa"&gt;
&lt;h4&gt;POA_CODE_2016: Postal Areas (POA)&lt;/h4&gt;
&lt;p&gt;It is recorded like POA3000. 3000 is the postal code. All postal code in Victoria, Australia has 4 digits and starts with 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="income-per-sex-per-age"&gt;
&lt;h4&gt;Income per Sex Per Age&lt;/h4&gt;
&lt;p&gt;Sex is denoated by:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;M for Male,&lt;/li&gt;
&lt;li&gt;F for Female,&lt;/li&gt;
&lt;li&gt;P for Persons (all sexes).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ages are grouped in:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;15-19: 15_19_yrs&lt;/li&gt;
&lt;li&gt;20-24: 20_24_yrs&lt;/li&gt;
&lt;li&gt;25-34: 25_34_yrs&lt;/li&gt;
&lt;li&gt;35-44: 35_44_yrs&lt;/li&gt;
&lt;li&gt;45-54: 45_54_yrs&lt;/li&gt;
&lt;li&gt;55-64: 55_64_yrs&lt;/li&gt;
&lt;li&gt;65-74: 65_74_yrs&lt;/li&gt;
&lt;li&gt;75-84: 75_84_yrs&lt;/li&gt;
&lt;li&gt;85 and over: 85_yrs_ovr or 85ov&lt;/li&gt;
&lt;li&gt;Total: Tot&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Weekly Income are denoated by:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Negative/Nil income: Neg_Nil_income&lt;/li&gt;
&lt;li&gt;$1-$149: 1_149&lt;/li&gt;
&lt;li&gt;$150-$299: 150_299&lt;/li&gt;
&lt;li&gt;$300-$399: 300_399&lt;/li&gt;
&lt;li&gt;$400-$499: 400_499&lt;/li&gt;
&lt;li&gt;$500-$649: 500_649&lt;/li&gt;
&lt;li&gt;$650-$799: 650_799&lt;/li&gt;
&lt;li&gt;$800-$999: 800_999&lt;/li&gt;
&lt;li&gt;$1,000-$1,249: 1000_1249&lt;/li&gt;
&lt;li&gt;$1,250-$1,499: 1250_1499&lt;/li&gt;
&lt;li&gt;$1,500-$1,749: 1500_1749&lt;/li&gt;
&lt;li&gt;$1,750-$1,999: 1750_1999&lt;/li&gt;
&lt;li&gt;$2,000-$2,999: 2000_2999&lt;/li&gt;
&lt;li&gt;$3,000 or more: 3000_more&lt;/li&gt;
&lt;li&gt;Personal income not stated: PI_NS_ns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore:&lt;/p&gt;
&lt;p&gt;F_300_399_Tot represents:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Female&lt;/li&gt;
&lt;li&gt;Weekly income between 300 and 399&lt;/li&gt;
&lt;li&gt;Across all age groups (total)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;P_PI_NS_ns_25_34_yrs:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Persons (male, female or others)&lt;/li&gt;
&lt;li&gt;Personal Income not stated&lt;/li&gt;
&lt;li&gt;Age between 25 to 34&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="literature-review"&gt;
&lt;h3&gt;Literature Review&lt;/h3&gt;
&lt;p&gt;Search by keywords: gender income inequality&lt;/p&gt;
&lt;p&gt;Data from the 1976 Australian census, which allow some assessment of how worker characteristics and the sex-typing of jobs affect the lower incomes of women, lead to the general conclusion that, while direct wage discrimination may have been virtually eliminated, occupational segregation by gender, discontinuous career patterns and part-time employment continue to depress the earnings of women.&lt;/p&gt;
&lt;p&gt;Citation:&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;F. L. Jones&lt;/cite&gt;; Sources of Gender Inequality in Income: What the Australian Census Says, Social Forces, Volume 62, Issue 1, 1 September 1983, Pages 134–152, &lt;a class="reference external" href="https://doi.org/10.1093/sf/62.1.134"&gt;https://doi.org/10.1093/sf/62.1.134&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Search by keywords: income residence OR income postal (zip) code&lt;/p&gt;
&lt;p&gt;For income and residence, probably because this type of data is collected directly so I cannot really find any paper talking about this. Most people probably treat the association of income and residence as common sense. I am interested in examining it by statistical measure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="hypothesis"&gt;
&lt;h3&gt;Hypothesis&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Australian Females earn significant less weekly than their male counterparts.&lt;/li&gt;
&lt;li&gt;Australians' weekly income is linked to where they live.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/research-project-1-for-data-visualization/</guid><pubDate>Sun, 27 Aug 2017 11:46:31 GMT</pubDate></item><item><title>My journey to Applied Data Science with Python and recent hobbies</title><link>http://www.datamofa.club/posts/my-journey-to-applied-data-science-with-python-and-recent-hobbies/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;div class="section" id="online-course"&gt;
&lt;h2&gt;Online Course&lt;/h2&gt;
&lt;p&gt;I'm doing Applied Data Science courses on Coursera. I finally paid my tuition after Coursera limited assessed participation to only paid users. After successfully completing the first course, I made the jump.&lt;/p&gt;
&lt;p&gt;I was a bit more skillful in the second course. For a start, I passed it with a first try and I also know more ways to get help I need. I have a feeling it's not as "hard" as the first course - Introduction to Data Science in Python (mainly pandas). But it's a false perception. I did spend a lot of time getting my way around knowing stackoverflow, Dash and online documentations, Jupyter notebook and good books/videos on Safarionline.&lt;/p&gt;
&lt;p&gt;My second course, Applied Plotting, Charting &amp;amp; Data Representation in Python, still need my Pandas skill, but the main focus in on evaluation of a good chart, Matplotlib and a little bit of seaborn. I find the introduction to Seaborn very limited and I wish Bokeh was included. We have an assignment where I created a semi-interaction chart, it was a pain to do that in Matplotlib. I believe it will be easier with Bokeh but I haven't learnt it so we will see later.&lt;/p&gt;
&lt;p&gt;At the beginning, I thought talking about chartjunk and how to evaluate charts is a bit airy fairy but later into the course, when I peer-assessed other classmates' work, I noticed that people tended to focus a lot on the programming techniques and still did not take in the advice from the Principles of Information Visualization. Then I realised how important it is.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="study-statistics"&gt;
&lt;h2&gt;Study Statistics&lt;/h2&gt;
&lt;p&gt;In this course, I find myself limited by my statistcal knowledge and I barely try to analyse data in that way. So I'm going to catch up now. Also, I'm a bit scared by the next course Applied Machine Learning in Python.&lt;/p&gt;
&lt;p&gt;I find this interesting book on Safarionline, &lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/practical-statistics-for/9781491952955/"&gt;Practical Statistics for Data Scientists&lt;/a&gt;. It seems readable for my level but unfortunately, its code is in R. I plan to converse it and share here: &lt;a class="reference external" href="https://github.com/jeremy886/learn-stats"&gt;https://github.com/jeremy886/learn-stats&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recent-hobbies"&gt;
&lt;h2&gt;Recent hobbies&lt;/h2&gt;
&lt;p&gt;After watching Uncle Bob's Clean Code on Safarionline and Youtube talks and reading many of his blogs, I am tempted to fiddle with Clojure or even Java (I had an two-decade old SCJP certificate). But I don't think a full time high school teacher can handle too many new languages. I better concentrate on Python. But to satisfy my curious mind, I might try Hy wit &lt;a class="reference external" href="https://mitpress.mit.edu/sicp/"&gt;SICP&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="an-interesting-video"&gt;
&lt;h2&gt;An interesting Video&lt;/h2&gt;
&lt;p&gt;"The Programming Language Called Classical Chinese" by David Branner&lt;/p&gt;
&lt;div class="youtube-video align-center"&gt;
&lt;iframe width="425" height="344" src="https://www.youtube.com/embed/vBhg2p8aAQ0?rel=0&amp;amp;hd=1&amp;amp;wmode=transparent"&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/my-journey-to-applied-data-science-with-python-and-recent-hobbies/</guid><pubDate>Wed, 29 Mar 2017 10:25:11 GMT</pubDate></item><item><title>Selected self-paced online courses to study (2017 Q1)</title><link>http://www.datamofa.club/posts/selected-self-paced-online-courses-to-study-2017-q1/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;Here are my choices of courses to study in 2017 Q1 to advance my career in Data Science.&lt;/p&gt;
&lt;div class="section" id="python-programming-skills"&gt;
&lt;h2&gt;Python Programming Skills&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/intermediate-python-programming/9781491954935/video248760.html"&gt;Intermediate Python Programming&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/python-in-a/9781491913833/"&gt;Python in a nutshell, 3rd edition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/python-programming-language/9780134217314/"&gt;David Beazley's Python Programming Language&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python Cookbook&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/making-classes-support/9781491965276/"&gt;https://www.safaribooksonline.com/library/view/making-classes-support/9781491965276/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/implementing-stateful-objects/9781491965283/"&gt;https://www.safaribooksonline.com/library/view/implementing-stateful-objects/9781491965283/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python Internal&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://youtu.be/HVUTjQzESeo"&gt;Allison Kaptur - Bytes in the Machine: Inside the CPython interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://pgbovine.net/cpython-internals.htm"&gt;CPython internals: A ten-hour codewalk through the Python interpreter source code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="computer-science"&gt;
&lt;h2&gt;Computer Science&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/working-with-algorithms/9781491907818/video182074.html"&gt;Algorithms with Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/designing-data-structures/9781491928622/"&gt;Data Structure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="data-visualization"&gt;
&lt;h2&gt;Data Visualization&lt;/h2&gt;
&lt;p&gt;Video &lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/python-data-visualization/9781787122802"&gt;https://www.safaribooksonline.com/library/view/python-data-visualization/9781787122802&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Book &lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/python-data-visualization/9781784396695/"&gt;https://www.safaribooksonline.com/library/view/python-data-visualization/9781784396695/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="natural-language-processing"&gt;
&lt;h2&gt;Natural Language Processing&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/natural-language-text/9781491976487/"&gt;Natural Language Text Processing with Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NLTK3 &lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/natural-language-processing/9781787285101/"&gt;https://www.safaribooksonline.com/library/view/natural-language-processing/9781787285101/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="websites"&gt;
&lt;h2&gt;Websites&lt;/h2&gt;
&lt;p&gt;Realpython part 2&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://django.readthedocs.io/en/latest/intro/tutorial01.html"&gt;http://django.readthedocs.io/en/latest/intro/tutorial01.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://training.talkpython.fm/courses/explore_entrepreneurs/python-for-entrepreneurs-build-and-launch-your-online-business"&gt;https://training.talkpython.fm/courses/explore_entrepreneurs/python-for-entrepreneurs-build-and-launch-your-online-business&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="sql"&gt;
&lt;h2&gt;SQL&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/essential-sqlalchemy-2nd/9781491916544/"&gt;https://www.safaribooksonline.com/library/view/essential-sqlalchemy-2nd/9781491916544/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="coursera"&gt;
&lt;h2&gt;Coursera&lt;/h2&gt;
&lt;p&gt;I'm waiting for this course to start: &lt;a class="reference external" href="https://www.coursera.org/learn/python-plotting"&gt;Applied Plotting, Charting &amp;amp; Data Representation in Python&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="advanced-topics"&gt;
&lt;h2&gt;Advanced Topics&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/python-machine-learning/9781787128033/"&gt;Python Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="topics-of-interest"&gt;
&lt;h2&gt;Topics of Interest&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.futurelearn.com/courses/creative-coding/"&gt;Creative Coding (using Processing.py)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Micropython for IoT (ESP8826)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/strata-hadoop/9781491944608/part50.html"&gt;BokehIntro to data visualization with Bokeh - Part 1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.safaribooksonline.com/library/view/strata-hadoop/9781491944608/part51.html"&gt;BokehIntro to data visualization with Bokeh - Part 2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lines-or-less"&gt;
&lt;h2&gt;500 Lines or Less&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://aosabook.org/en/index.html"&gt;500 lines or less&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;AsyncIO&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html"&gt;reading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://pgbovine.net/python-async-io-walkthrough.htm"&gt;video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="more-courses"&gt;
&lt;h2&gt;More Courses?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://universe.openai.com/"&gt;https://universe.openai.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>2017Q1</category><category>courses</category><guid>http://www.datamofa.club/posts/selected-self-paced-online-courses-to-study-2017-q1/</guid><pubDate>Mon, 30 Jan 2017 02:53:54 GMT</pubDate></item><item><title>My first pytest experience</title><link>http://www.datamofa.club/posts/my-first-pytest-experience/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;This is my first time with pytest. It was amazing simple (Of course, I ignored all difficult parts).&lt;/p&gt;
&lt;script src="https://gist.github.com/95fe6097d06b5d3eef2f93c3dcff1b36.js"&gt;&lt;/script&gt;&lt;noscript&gt;&lt;pre class="literal-block"&gt;
__author__ = 'Jeremy Chen'


def merge_sort(unsorted):

    sorted_ = []
    length = len(unsorted)
    if length == 1:
        sorted_ = unsorted

    elif length == 2:
        left = unsorted[:length//2]
        right = unsorted[length//2:]

        if left[0] &amp;gt;= right[0]:
            sorted_ = right + left
        else:
            sorted_ = left + right

    elif length == 3:
        left_sorted = merge_sort(unsorted[:length//2])
        right_sorted = merge_sort(unsorted[length//2:])

        if left_sorted[0] &amp;lt;= right_sorted[0]:
            sorted_.append(left_sorted[0])
            sorted_.append(right_sorted[0])
            sorted_.append(right_sorted[1])

        elif left_sorted[0] &amp;lt;= right_sorted[1]:
            sorted_.append(right_sorted[0])
            sorted_.append(left_sorted[0])
            sorted_.append(right_sorted[1])
        else:
            sorted_.append(right_sorted[0])
            sorted_.append(right_sorted[1])
            sorted_.append(left_sorted[0])

    elif length &amp;gt;= 4:
        left_sorted = merge_sort(unsorted[:length//2])
        right_sorted = merge_sort(unsorted[length//2:])

        l, r = 0, 0
        for i in range(length):
            if l == len(left_sorted):
                sorted_.append(right_sorted[r])
                r += 1
            elif r == len(right_sorted):
                sorted_.append(left_sorted[l])
                l += 1
            elif left_sorted[l] &amp;lt; right_sorted[r]:
                sorted_.append(left_sorted[l])
                l += 1
            else:
                sorted_.append(right_sorted[r])
                r += 1
    return sorted_



def test_one_num():
    assert merge_sort([1]) == [1]

def test_two_nums():
    assert merge_sort([1, 2]) == [1, 2]
    assert merge_sort([2, 1]) == [1, 2]
    assert merge_sort([4, 3]) == [3, 4]

def test_three_nums():
    assert merge_sort([1, 2, 3]) == [1, 2, 3]
    assert merge_sort([1, 3, 2]) == [1, 2, 3]
    assert merge_sort([2, 1, 3]) == [1, 2, 3]
    assert merge_sort([2, 3, 1]) == [1, 2, 3]
    assert merge_sort([3, 1, 2]) == [1, 2, 3]
    assert merge_sort([3, 2, 1]) == [1, 2, 3]


def test_any_nums():
    assert merge_sort([5, 4, 3, 2, 1]) == [1, 2, 3, 4, 5]
    assert merge_sort([99, 34, 3, -19, -8, 7, 45]) == [-19, -8, 3, 7, 34, 45, 99]

&lt;/pre&gt;
&lt;/noscript&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/my-first-pytest-experience/</guid><pubDate>Thu, 19 Jan 2017 01:52:13 GMT</pubDate></item><item><title>Start a new adventure into Data Science in 2017</title><link>http://www.datamofa.club/posts/start-a-new-adventure-into-data-science-in-2017/</link><dc:creator>Jeremy Chen</dc:creator><description>&lt;div&gt;&lt;p&gt;It's my holiday so I have some free time at hand to explore things I'm curious.&lt;/p&gt;
&lt;p&gt;I also want to venture out more.&lt;/p&gt;&lt;/div&gt;</description><guid>http://www.datamofa.club/posts/start-a-new-adventure-into-data-science-in-2017/</guid><pubDate>Fri, 13 Jan 2017 06:51:09 GMT</pubDate></item></channel></rss>